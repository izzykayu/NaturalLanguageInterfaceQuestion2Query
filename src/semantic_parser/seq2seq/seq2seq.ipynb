{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This class generates vocabulary and word2index and index2word on any corpus\n",
    "class Language():\n",
    "    def __init__(self, filename, filter_special_characters, word_count_threshold, special_symbols_list, pretrained_word2vec_path=None, word_embedding_dim=None):\n",
    "        self.contents = self.read_file(filename)\n",
    "        self.contents = self.normalize_file_contents(self.contents, filter_special_characters)\n",
    "        self.vocabulary = self.generate_vocabulary(self.contents, word_count_threshold, special_symbols_list)\n",
    "        self.word2index = self.generate_word2index(self.vocabulary)\n",
    "        self.index2word = self.generate_index2word(self.vocabulary)\n",
    "        self.filter_special_characters = filter_special_characters\n",
    "        self.special_symbols_list = special_symbols_list\n",
    "        if pretrained_word2vec_path is not None and word_embedding_dim is not None:\n",
    "            self.word_embedding_dim = word_embedding_dim\n",
    "            self.word_embeddings = self.initialize_word_vectors(pretrained_word2vec_path)\n",
    "        else:\n",
    "            self.word_embedding_dim = None\n",
    "            self.word_embeddings = None\n",
    "            \n",
    "    # Returns contents of a file as list of sentences\n",
    "    def read_file(self, filename):\n",
    "        _file = open(filename,'r')\n",
    "        contents = []\n",
    "        for line in _file:\n",
    "            contents.append(line)\n",
    "        _file.close()\n",
    "        return contents\n",
    "\n",
    "    # Lowercase, trim, and remove filter_special_characters \n",
    "    def normalize_file_contents(self, contents, filter_special_characters):\n",
    "        normalized_contents = []\n",
    "        for line in contents:\n",
    "            line = line.lower().strip()\n",
    "            line = line.translate(None, filter_special_characters)\n",
    "            normalized_contents.append(line.split())\n",
    "        return normalized_contents\n",
    "\n",
    "    # Returns the vocabulary- words below a threshold are dropped and special symbols are added(SOS, EOS)   \n",
    "    def generate_vocabulary(self, contents, word_count_threshold, special_symbols_list):\n",
    "        vocab = []\n",
    "        for special_symbols in special_symbols_list:\n",
    "            vocab.append(special_symbols)  \n",
    "\n",
    "        counter = Counter()\n",
    "        for line in contents:\n",
    "            counter.update(line)\n",
    "\n",
    "        for word,count in counter.iteritems():\n",
    "            if count > word_count_threshold:\n",
    "                vocab.append(word)\n",
    "        return vocab\n",
    "\n",
    "    # maps word to index\n",
    "    def generate_word2index(self, vocabulary):\n",
    "        word2index = {}\n",
    "        for index, word in enumerate(vocabulary):\n",
    "            word2index[word] = index\n",
    "        return word2index\n",
    "\n",
    "    # maps index to word\n",
    "    def generate_index2word(self, vocabulary):\n",
    "        index2word = {}\n",
    "        for index, word in enumerate(vocabulary):\n",
    "            index2word[index] = word\n",
    "        return index2word\n",
    "    \n",
    "    def initialize_word_vectors(self, pretrained_word2vec_path):\n",
    "        word2vec_model = KeyedVectors.load_word2vec_format(pretrained_word2vec_path, binary=True)\n",
    "        word_vectors = np.random.uniform(-0.1, 0.1, (len(self.vocabulary), self.word_embedding_dim))\n",
    "        for index, word in self.index2word.iteritems():\n",
    "            if word in word2vec_model:\n",
    "                word_vectors[index, :] = word2vec_model[word]\n",
    "        return word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sourceLanguage = Language(filename= '../training_data/geo_tr.nl.tem',\n",
    "                          filter_special_characters= string.punctuation.translate(None, '@'),\n",
    "                          word_count_threshold= 1,\n",
    "                          special_symbols_list=['<sos>','<eos>','<unk>'],\n",
    "                          pretrained_word2vec_path='/scratch/at3577/GoogleNews-vectors-negative300.bin', \n",
    "                          word_embedding_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# had to add unkown in sql vocab--> Check this\n",
    "targetLanguage = Language(filename= '../training_data/geo_tr.sql.tem',\n",
    "                          filter_special_characters= '',\n",
    "                          word_count_threshold= 1,\n",
    "                          special_symbols_list= ['<sos>','<eos>','<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This class is used to load the dataset\n",
    "class Nl2SqlDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        source = self.dataframe.iloc[idx, 0]\n",
    "        target = self.dataframe.iloc[idx, 1]\n",
    "        \n",
    "        sample = {'nl': source, 'sql': target}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "\n",
    "# Transformers:\n",
    "# 1. Lowercase, trim, and remove filter_special_characters\n",
    "# 2. add SOS, EOS and UNK to the sentence\n",
    "# 3. converts sentence to index\n",
    "# 4. to tensor\n",
    "\n",
    "class Transformer(object):\n",
    "    \n",
    "    def __init__(self, sourceLanguage, targetLanguage):\n",
    "        self.source_language = sourceLanguage\n",
    "        self.target_language = targetLanguage\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        nl, sql = sample['nl'], sample['sql']\n",
    "        \n",
    "        # 1. Lowercase, trim, and remove filter_special_characters\n",
    "        nl  = self.normalize_line(nl, self.source_language.filter_special_characters)\n",
    "        sql = self.normalize_line(sql, self.target_language.filter_special_characters)\n",
    "        \n",
    "        # 2. add SOS, EOS and UNK to the sentence\n",
    "        nl = self.replace_unknown_words(nl, self.source_language, self.source_language.special_symbols_list[2])\n",
    "        sql = self.replace_unknown_words(sql, self.target_language, self.target_language.special_symbols_list[2])\n",
    "        nl = [self.source_language.special_symbols_list[0]] + nl + [self.source_language.special_symbols_list[1]]\n",
    "        sql= [self.target_language.special_symbols_list[0]] + sql + [self.target_language.special_symbols_list[1]]\n",
    "        \n",
    "        # 3. converts sentence to index\n",
    "        nl  = self.sentence2index(nl, self.source_language)\n",
    "        sql = self.sentence2index(sql, self.target_language)\n",
    "        \n",
    "        # 4. to tensor\n",
    "        nl = torch.LongTensor(nl)\n",
    "        sql = torch.LongTensor(sql)\n",
    "        \n",
    "        return {'nl': nl, 'sql': sql}\n",
    "    \n",
    "    def normalize_line(self, line, filter_special_characters):\n",
    "        line = line.lower().strip()\n",
    "        line = line.translate(None, filter_special_characters)\n",
    "        line = line.split()\n",
    "        return line\n",
    "\n",
    "    def replace_unknown_words(self, sentence, language, unknown_symbol):\n",
    "        for idx, word in enumerate(sentence):\n",
    "            if word not in language.vocabulary:\n",
    "                sentence[idx] = unknown_symbol\n",
    "        return sentence\n",
    "    \n",
    "    def sentence2index(self, sentence, language):\n",
    "        new_sentence = []\n",
    "        for word in sentence:\n",
    "            new_sentence.append(language.word2index[word])\n",
    "        return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_dataset = Nl2SqlDataset('../training_data/geo_train.tem.csv', transform=Transformer(sourceLanguage, targetLanguage))\n",
    "dev_dataset = Nl2SqlDataset('../training_data/geo_dev.tem.csv', transform=Transformer(sourceLanguage, targetLanguage))\n",
    "test_dataset = Nl2SqlDataset('../training_data/geo_test.tem.csv', transform=Transformer(sourceLanguage, targetLanguage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, source_language, lstm_hidden_size, lstm_num_layers, dropout_prob):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_embeddings = len(source_language.vocabulary)\n",
    "        self.embedding_dim = source_language.word_embedding_dim\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.lstm_num_layers = lstm_num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.num_embeddings, self.embedding_dim)\n",
    "        self.bilstm = nn.LSTM(input_size=self.embedding_dim, \n",
    "                              hidden_size= lstm_hidden_size,\n",
    "                              num_layers= lstm_num_layers,\n",
    "                              bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "        self.initialize_embeddings(source_language.word_embeddings)\n",
    "        \n",
    "    def initialize_embeddings(self, initial_word_embeddings):\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(initial_word_embeddings))\n",
    "    \n",
    "    def forward(self, source_language_sentence):\n",
    "        \n",
    "        embedded  = self.embedding(source_language_sentence)\n",
    "        embedded  = self.dropout(embedded)\n",
    "        \n",
    "        seq_len = len(source_language_sentence)\n",
    "        bilstm_input = embedded.view(seq_len, 1, self.embedding_dim)\n",
    "        \n",
    "        output, (hidden_state, cell_state) = self.bilstm(bilstm_input)\n",
    "        \n",
    "        return output, hidden_state, cell_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self, target_language, encoder, target_embedding_dim, lstm_num_layers, dropout_prob):\n",
    "        super(AttnDecoder, self).__init__()\n",
    "        self.num_embeddings = len(target_language.vocabulary)\n",
    "        self.embedding_dim = target_embedding_dim\n",
    "        self.lstm_hidden_size = encoder.lstm_hidden_size\n",
    "        self.lstm_num_layers = lstm_num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.num_embeddings, self.embedding_dim)\n",
    "        self.bilstm = nn.LSTM(input_size=self.embedding_dim + encoder.lstm_hidden_size*2,\n",
    "                              hidden_size=self.lstm_hidden_size,\n",
    "                              num_layers= lstm_num_layers,\n",
    "                              bidirectional=True)\n",
    "        self.output_layer = nn.Linear(self.lstm_hidden_size*2 + encoder.lstm_hidden_size*2, len(target_language.vocabulary))\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self, target_language_word, hidden_state, cell_state, encoder_outputs):\n",
    "        \n",
    "        #1 Embedding layer\n",
    "        embedded = self.embedding(target_language_word)\n",
    "        embedded  = self.dropout(embedded)\n",
    "        bilstm_input = embedded.view(1, 1, self.embedding_dim)\n",
    "       \n",
    "        #2 Attention layer\n",
    "        attn_weights = self.attn(hidden_state, encoder_outputs) #(1, 1, seqlen)\n",
    "        context = torch.bmm(attn_weights, torch.transpose(encoder_outputs, 0, 1)) #(1,1,2*encoder_lstm_hidden_size)\n",
    "        \n",
    "        #3 Bilstm\n",
    "        bilstm_input = torch.cat((bilstm_input, context), 2)\n",
    "        bilstm_output, (hidden_state, cell_state) = self.bilstm(bilstm_input, (hidden_state, cell_state))\n",
    "        \n",
    "        #4 Output Layer\n",
    "        output_layer_input = torch.cat((bilstm_output, context), 2)\n",
    "        output_layer_input = torch.squeeze(output_layer_input, 0) #(1, self.lstm_hidden_size*2 + encoder.lstm_hidden_size*2)\n",
    "        output = self.softmax(self.output_layer(output_layer_input)) #(1, len(target_language.vocabulary))\n",
    "        \n",
    "        return output, hidden_state, cell_state \n",
    "    \n",
    "    def attn(self, hidden_state, encoder_outputs):\n",
    "        seqlen = len(encoder_outputs)\n",
    "        attn_energies = Variable(torch.zeros(seqlen))\n",
    "        \n",
    "        for i in range(seqlen):\n",
    "            attn_energies[i] = torch.dot(hidden_state.view(1,-1), encoder_outputs[i])\n",
    "        \n",
    "        return F.softmax(attn_energies).unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(source_language_sentence, target_language_sentence, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, clip_gradient):\n",
    "    # set training to true for dropout layers\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    # Get size of input and target sentences\n",
    "    input_length = source_language_sentence.size()[0]\n",
    "    target_length = target_language_sentence.size()[0]\n",
    "    \n",
    "    # Run words through encoder\n",
    "    encoder_outputs, encoder_hidden_state, encoder_cell_state = encoder(source_language_sentence)\n",
    "    # encoder_outputs -> (input_length, 1, 2*encoder_hidden_size)\n",
    "    # encoder_hidden_state -> (2, 1, encoder_hidden_size)\n",
    "\n",
    "    # Prepare decoder input and output\n",
    "    decoder_hidden_state = encoder_hidden_state\n",
    "    decoder_cell_state = Variable(torch.zeros(decoder_hidden_state.shape[0], decoder_hidden_state.shape[1], decoder_hidden_state.shape[2]))\n",
    "    \n",
    "    #only using teacher forcing for now --> Check this\n",
    "    loss = 0\n",
    "    for i in range(target_length-1):\n",
    "        decoder_output, decoder_hidden_state, decoder_cell_state = decoder(target_language_sentence[i].view(1,1), decoder_hidden_state, decoder_cell_state, encoder_outputs)\n",
    "        loss += criterion(decoder_output, target_language_sentence[i+1])\n",
    "    \n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip_gradient)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip_gradient)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(dataset, num_samples, source_language, target_language, encoder, decoder, criterion, verbose=False):\n",
    "    # set training to false for dropout layers\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    for n_sample in range(num_samples):\n",
    "        sample = random.choice(dataset)\n",
    "        source_language_sentence, target_language_sentence = Variable(sample['nl']), Variable(sample['sql'])\n",
    "        \n",
    "        # Get size of input and target sentences\n",
    "        input_length = source_language_sentence.size()[0]\n",
    "        target_length = target_language_sentence.size()[0]\n",
    "\n",
    "        # Run words through encoder\n",
    "        encoder_outputs, encoder_hidden_state, encoder_cell_state = encoder(source_language_sentence)\n",
    "        # encoder_outputs -> (input_length, 1, 2*encoder_hidden_size)\n",
    "        # encoder_hidden_state -> (2, 1, encoder_hidden_size)\n",
    "\n",
    "        # Prepare decoder input and output\n",
    "        decoder_hidden_state = encoder_hidden_state\n",
    "        decoder_cell_state = Variable(torch.zeros(decoder_hidden_state.shape[0], decoder_hidden_state.shape[1], decoder_hidden_state.shape[2]))\n",
    "        \n",
    "        loss = 0\n",
    "        decoder_input = target_language_sentence[0].view(1,1)\n",
    "        predicted_sentence = []\n",
    "        for i in range(target_length-1):\n",
    "            decoder_output, decoder_hidden_state, decoder_cell_state = decoder(decoder_input, decoder_hidden_state, decoder_cell_state, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_language_sentence[i+1])\n",
    "            \n",
    "            # Choose top word from output\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            if ni == target_language.word2index['<eos>']:\n",
    "                break\n",
    "            \n",
    "            # Next input is chosen word\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            predicted_sentence.append(ni)\n",
    "        \n",
    "        total_loss += (loss.data[0] / target_length)\n",
    "        if verbose:\n",
    "            print 'Sample ' + str(n_sample)\n",
    "            print 'Source sentence = ' + str(to_sentence(source_language_sentence.data.numpy(), source_language))\n",
    "            print 'Target sentence = ' + str(to_sentence(target_language_sentence.data.numpy(), target_language))\n",
    "            print 'Predicted sentence = ' + str(to_sentence(predicted_sentence, target_language))\n",
    "            \n",
    "    return total_loss/num_samples\n",
    "\n",
    "def to_sentence(index_list ,language):\n",
    "    sentence = []\n",
    "    for index in index_list:\n",
    "        sentence.append(language.index2word[index])\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize models, optimizers, and a loss function (criterion).\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_epochs = 70\n",
    "clip_gradient = 5.0\n",
    "\n",
    "encoder_lstm_hidden_size = 100\n",
    "encoder_lstm_num_layers=1\n",
    "encoder_dropout_prob = 0.05\n",
    "\n",
    "decoder_target_embedding_dim=100\n",
    "decoder_lstm_num_layers=1\n",
    "decoder_dropout_prob = 0.05\n",
    "\n",
    "encoder = Encoder(source_language= sourceLanguage, \n",
    "                  lstm_hidden_size= encoder_lstm_hidden_size, \n",
    "                  lstm_num_layers= encoder_lstm_num_layers,\n",
    "                  dropout_prob= encoder_dropout_prob)\n",
    "decoder = AttnDecoder(target_language= targetLanguage, \n",
    "                      encoder= encoder, \n",
    "                      target_embedding_dim= decoder_target_embedding_dim, \n",
    "                      lstm_num_layers= decoder_lstm_num_layers,\n",
    "                      dropout_prob= decoder_dropout_prob)\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/apps/python/2.7.12/intel/lib/python2.7/site-packages/ipykernel/__main__.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/share/apps/python/2.7.12/intel/lib/python2.7/site-packages/ipykernel/__main__.py:36: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss after 0 epoch is 2.34918565239 dev loss= 2.79009614308\n",
      "Training loss after 1 epoch is 1.18248255008 dev loss= 0.978354665005\n",
      "Training loss after 2 epoch is 0.909983075366 dev loss= 2.97970072684\n",
      "Training loss after 3 epoch is 0.666269725064 dev loss= 1.09290291233\n",
      "Training loss after 4 epoch is 0.521183725227 dev loss= 1.05054347827\n",
      "Training loss after 5 epoch is 0.566855149908 dev loss= 0.788777080448\n",
      "Training loss after 6 epoch is 0.475540507664 dev loss= 1.02768390516\n",
      "Training loss after 7 epoch is 0.367422926599 dev loss= 3.0183724603\n",
      "Training loss after 8 epoch is 0.307633093168 dev loss= 1.97985460852\n",
      "Training loss after 9 epoch is 0.347964972196 dev loss= 0.730826035631\n",
      "Training loss after 10 epoch is 0.306614356182 dev loss= 1.17525478998\n",
      "Training loss after 11 epoch is 0.280709338214 dev loss= 2.01325208534\n",
      "Training loss after 12 epoch is 0.310613128013 dev loss= 1.45970614895\n",
      "Training loss after 13 epoch is 0.217434537436 dev loss= 0.339680945315\n",
      "Training loss after 14 epoch is 0.204497986208 dev loss= 2.3070330446\n",
      "Training loss after 15 epoch is 0.201822964793 dev loss= 0.853716898629\n",
      "Training loss after 16 epoch is 0.189386493016 dev loss= 0.69658955921\n",
      "Training loss after 17 epoch is 0.186239397606 dev loss= 0.404626047124\n",
      "Training loss after 18 epoch is 0.174084150682 dev loss= 0.177098546569\n",
      "Training loss after 19 epoch is 0.195169265098 dev loss= 0.271683324368\n",
      "Training loss after 20 epoch is 0.191278928066 dev loss= 1.67995364379\n",
      "Training loss after 21 epoch is 0.22430141904 dev loss= 0.878282286505\n",
      "Training loss after 22 epoch is 0.103862858454 dev loss= 0.42403778698\n",
      "Training loss after 23 epoch is 0.150313778027 dev loss= 0.718680974272\n",
      "Training loss after 24 epoch is 0.102346065026 dev loss= 0.627140076005\n",
      "Training loss after 25 epoch is 0.142918068465 dev loss= 0.768560802492\n",
      "Training loss after 26 epoch is 0.132797089543 dev loss= 0.654062433833\n",
      "Training loss after 27 epoch is 0.076923845912 dev loss= 2.38157871841\n",
      "Training loss after 28 epoch is 0.112634057369 dev loss= 2.51627244963\n",
      "Training loss after 29 epoch is 0.119037565827 dev loss= 0.851158170336\n",
      "Training loss after 30 epoch is 0.0785182449654 dev loss= 0.928435963371\n",
      "Training loss after 31 epoch is 0.082544377962 dev loss= 0.733539671491\n",
      "Training loss after 32 epoch is 0.0636368863457 dev loss= 0.939211794889\n",
      "Training loss after 33 epoch is 0.0936852325401 dev loss= 1.39991328867\n",
      "Training loss after 34 epoch is 0.0954023438724 dev loss= 0.515887604612\n",
      "Training loss after 35 epoch is 0.0976838935205 dev loss= 0.521981752296\n",
      "Training loss after 36 epoch is 0.0608560538733 dev loss= 1.21132869607\n",
      "Training loss after 37 epoch is 0.0615894158301 dev loss= 1.5601541649\n",
      "Training loss after 38 epoch is 0.051056193052 dev loss= 0.898586540797\n",
      "Training loss after 39 epoch is 0.0374240036899 dev loss= 0.401308448441\n",
      "Training loss after 40 epoch is 0.097755060322 dev loss= 1.00659200285\n",
      "Training loss after 41 epoch is 0.0552433825812 dev loss= 2.56846452309\n",
      "Training loss after 42 epoch is 0.0773379006116 dev loss= 0.263673180259\n",
      "Training loss after 43 epoch is 0.0851182536812 dev loss= 0.303718542214\n",
      "Training loss after 44 epoch is 0.0598914404154 dev loss= 1.8806779971\n",
      "Training loss after 45 epoch is 0.0551605162676 dev loss= 0.152942470735\n",
      "Training loss after 46 epoch is 0.0430248539224 dev loss= 0.189625447653\n",
      "Training loss after 47 epoch is 0.0355237418644 dev loss= 2.20584042193\n",
      "Training loss after 48 epoch is 0.0950298800494 dev loss= 0.68168335839\n",
      "Training loss after 49 epoch is 0.0331631477073 dev loss= 0.982150857858\n",
      "Training loss after 50 epoch is 0.0735637168987 dev loss= 1.30342540542\n",
      "Training loss after 51 epoch is 0.0646456736168 dev loss= 0.0964545405993\n",
      "Training loss after 52 epoch is 0.0497459698796 dev loss= 0.80647430762\n",
      "Training loss after 53 epoch is 0.0615163626571 dev loss= 1.33885468569\n",
      "Training loss after 54 epoch is 0.0300338933424 dev loss= 0.578316034899\n",
      "Training loss after 55 epoch is 0.0474988030035 dev loss= 0.617257747772\n",
      "Training loss after 56 epoch is 0.0520103015959 dev loss= 2.79796229933\n",
      "Training loss after 57 epoch is 0.00966002663959 dev loss= 2.10641965844\n",
      "Training loss after 58 epoch is 0.0413907263104 dev loss= 0.644900016159\n",
      "Training loss after 59 epoch is 0.0267904941529 dev loss= 0.56107417836\n",
      "Training loss after 60 epoch is 0.0344699189182 dev loss= 0.190117275102\n",
      "Training loss after 61 epoch is 0.0277833936324 dev loss= 2.98684208543\n",
      "Training loss after 62 epoch is 0.0441627988395 dev loss= 1.56795580797\n",
      "Training loss after 63 epoch is 0.0531093271133 dev loss= 0.309518093205\n",
      "Training loss after 64 epoch is 0.0211813198345 dev loss= 1.36564428646\n",
      "Training loss after 65 epoch is 0.0368357149592 dev loss= 1.7171196429\n",
      "Training loss after 66 epoch is 0.0418801224299 dev loss= 0.0433968959803\n",
      "Training loss after 67 epoch is 0.0272847757736 dev loss= 0.160025368054\n",
      "Training loss after 68 epoch is 0.0179378454027 dev loss= 1.7930949015\n",
      "Training loss after 69 epoch is 0.0368362311427 dev loss= 0.295952562132\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "for n_epochs in range(num_epochs):\n",
    "    training_loss = 0\n",
    "    for batch in range(batch_size):\n",
    "        sample = random.choice(training_dataset)\n",
    "        source_language_sentence, target_language_sentence = Variable(sample['nl']), Variable(sample['sql'])\n",
    "        training_loss += train(source_language_sentence, target_language_sentence, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, clip_gradient)\n",
    "    \n",
    "    training_loss = training_loss/batch_size\n",
    "    dev_loss = evaluate(dev_dataset, 10, sourceLanguage, targetLanguage, encoder, decoder, criterion)\n",
    "    print 'Training loss after ' + str(n_epochs) + ' epoch is ' + str(training_loss) + ' dev loss= ' + str(dev_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/apps/python/2.7.12/intel/lib/python2.7/site-packages/ipykernel/__main__.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/share/apps/python/2.7.12/intel/lib/python2.7/site-packages/ipykernel/__main__.py:36: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0\n",
      "Source sentence = ['<sos>', 'what', 'states', 'border', 'state@0', '<eos>']\n",
      "Target sentence = ['<sos>', 'select', 'border_info.border', 'from', 'border_info', 'where', 'border_info.state_name', '=', 'state@0', ';', '<eos>']\n",
      "Predicted sentence = ['select', 'border_info.border', 'from', 'border_info', 'where', 'border_info.state_name', '=', 'state@0', ';']\n",
      "Sample 1\n",
      "Source sentence = ['<sos>', 'which', 'river', 'traverses', 'most', 'states', '<eos>']\n",
      "Target sentence = ['<sos>', 'select', 'river.river_name', 'from', 'river', 'group', 'by', '(', 'river.river_name', ')', 'order', 'by', 'count', '(', 'distinct', 'river.traverse', ')', 'desc', 'limit', '1', ';', '<eos>']\n",
      "Predicted sentence = ['select', 'river.river_name', 'from', 'river', 'group', 'by', '(', 'river.river_name', ')', 'order', 'by', 'count', '(', 'distinct', 'river.traverse', ')', 'desc', 'limit', '1', ';']\n",
      "Sample 2\n",
      "Source sentence = ['<sos>', 'what', 'is', 'the', 'most', 'populous', 'state', '<eos>']\n",
      "Target sentence = ['<sos>', 'select', 'state.state_name', 'from', 'state', 'where', 'state.population', '=', '(', 'select', 'max', '(', 'state.population', ')', 'from', 'state', ')', ';', '<eos>']\n",
      "Predicted sentence = ['select', 'state.state_name', 'from', 'state', 'where', 'state.population', '=', '(', 'select', 'max', '(', 'state.population', ')', 'from', 'state', ')', ';']\n",
      "Sample 3\n",
      "Source sentence = ['<sos>', 'what', 'is', 'the', 'capital', 'of', 'state@0', '<eos>']\n",
      "Target sentence = ['<sos>', 'select', 'state.capital', 'from', 'state', 'where', 'state.state_name', '=', 'state@0', ';', '<eos>']\n",
      "Predicted sentence = ['select', 'state.capital', 'from', 'state', 'where', 'state.state_name', '=', 'state@0', ';']\n",
      "Sample 4\n",
      "Source sentence = ['<sos>', 'what', 'is', 'capital', 'of', 'the', 'state', 'with', 'the', 'lowest', 'point', '<eos>']\n",
      "Target sentence = ['<sos>', 'select', 'state.capital', 'from', 'state', ',', 'highlow', 'where', 'state.state_name', '=', 'highlow.state_name', 'and', 'highlow.lowest_elevation', '=', '(', 'select', 'min', '(', 'highlow.lowest_elevation', ')', 'from', 'highlow', ')', ';', '<eos>']\n",
      "Predicted sentence = ['select', 'state.capital', 'from', 'state', ',', 'highlow', 'where', 'state.state_name', '=', 'highlow.state_name', 'and', 'highlow.highest_elevation', '=', '(', 'select', 'max', '(', 'highlow.highest_elevation', ')', 'from', 'highlow', ')', ';']\n",
      "Sample 5\n",
      "Source sentence = ['<sos>', 'what', 'is', 'the', 'population', 'of', 'state@0', '<eos>']\n",
      "Target sentence = ['<sos>', 'select', 'state.population', 'from', 'state', 'where', 'state.state_name', '=', 'state@0', ';', '<eos>']\n",
      "Predicted sentence = ['select', 'state.population', 'from', 'state', 'where', 'state.state_name', '=', 'state@0', ';']\n",
      "Sample 6\n",
      "Source sentence = ['<sos>', 'what', 'is', 'the', 'population', 'of', 'state@0', '<eos>']\n",
      "Target sentence = ['<sos>', 'select', 'state.population', 'from', 'state', 'where', 'state.state_name', '=', 'state@0', ';', '<eos>']\n",
      "Predicted sentence = ['select', 'state.population', 'from', 'state', 'where', 'state.state_name', '=', 'state@0', ';']\n",
      "Sample 7\n",
      "Source sentence = ['<sos>', 'what', 'is', 'the', 'highest', 'point', 'in', 'state@0', '<eos>']\n",
      "Target sentence = ['<sos>', 'select', 'highlow.highest_point', 'from', 'highlow', 'where', 'highlow.state_name', '=', 'state@0', ';', '<eos>']\n",
      "Predicted sentence = ['select', 'highlow.highest_point', 'from', 'highlow', 'where', 'highlow.state_name', '=', 'state@0', ';']\n",
      "Sample 8\n",
      "Source sentence = ['<sos>', 'how', 'long', 'is', 'the', 'river@0', 'river', '<eos>']\n",
      "Target sentence = ['<sos>', 'select', 'river.length', 'from', 'river', 'where', 'river.river_name', '=', 'river@0', ';', '<eos>']\n",
      "Predicted sentence = ['select', 'river.length', 'from', 'river', 'where', 'river.river_name', '=', 'river@0', ';']\n",
      "Sample 9\n",
      "Source sentence = ['<sos>', 'which', 'state', 'capital', 'has', 'the', 'smallest', 'population', '<eos>']\n",
      "Target sentence = ['<sos>', 'select', 'city.city_name', 'from', 'city', 'where', 'city.population', '=', '(', 'select', 'min', '(', 'city.population', ')', 'from', 'city', ',', 'state', 'where', 'city.city_name', '=', 'state.capital', ')', ';', '<eos>']\n",
      "Predicted sentence = ['select', 'state.state_name', 'from', 'state', 'where', 'state.population', '=', '(', 'select', 'max', '(', 'state.population', ')', 'from', 'state', ')', ';']\n"
     ]
    }
   ],
   "source": [
    "# Evaluating on small sample of test set\n",
    "test_loss = evaluate(test_dataset, 10, sourceLanguage, targetLanguage, encoder, decoder, criterion, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39442173794239455"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Incomplete Beam search-- fill it up or throw it and implement from scratch\n",
    "class State(object):\n",
    "    def __init__(self, decoder_input, decoder_hidden_state, decoder_cell_state, encoder_outputs, current_score, decoded_sentence):\n",
    "            self.decoder_input = decoder_input\n",
    "            self.decoder_hidden_state = decoder_hidden_state\n",
    "            self.decoder_cell_state = decoder_cell_state\n",
    "            self.encoder_outputs = encoder_outputs\n",
    "            self.current_score = current_score\n",
    "            self.decoded_sentence = decoded_sentence\n",
    "\n",
    "class BeamSearch(object):\n",
    "    def __init__(self, beam_size, decoder):\n",
    "        self.beam_size = beam_size\n",
    "        self.decoder = decoder\n",
    "        self.current_states = []\n",
    "        self.next_states = []\n",
    "    \n",
    "    # initialize first state in current state\n",
    "    def initialize_beam_search(self, decoder_input, decoder_hidden_state, decoder_cell_state, encoder_outputs):\n",
    "    \n",
    "    #performs one step of beam search\n",
    "    def forward(self):\n",
    "        for state in self.current_states:\n",
    "            decoder_output, decoder_hidden_state, decoder_cell_state = self.decoder(state.decoder_input, \n",
    "                                                                                    state.decoder_hidden_state, \n",
    "                                                                                    state.decoder_cell_state,\n",
    "                                                                                    state.encoder_outputs)\n",
    "            self.next_states.append(self.get_next_states(decoder_output, decoder_hidden_state, decoder_cell_state, state.encoder_outputs, state.current_score, state.decoded_sentence))\n",
    "        \n",
    "        self.current_states[:] = get_best_states(self.beam_size, self.next_states)\n",
    "        self.next_states[:] = []\n",
    "        \n",
    "    #computes the next states\n",
    "    def get_next_states():\n",
    "    \n",
    "    #sorts the states based on score\n",
    "    def get_best_states():\n",
    "    \n",
    "    def search(self):\n",
    "        self.initialize_beam_search()\n",
    "        # call forward in loop to perform one step of beam search \n",
    "        # do untill EOS is obtained"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
